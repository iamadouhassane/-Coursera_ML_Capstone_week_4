{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is a part of Cousera   Applied Data Science Capstone Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to download, clean and structure New York's and Canada's data cities  <a href=\"#item1\">on one aggregate data set with their geographical coordinates</a>. Thus, we can directly call and use this data set in the main notebook of this project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3>\n",
    "\n",
    "1. <a href=\"#item1\">Use python package BeautifulSoup  to scrap list of postal codes of Toronto</a>\n",
    "\n",
    "2. <a href=\"#item2\">Use the link http://cocl.us/Geospatial_data   to download Toronto's geographical coordinates directly</a>\n",
    "\n",
    "3. <a href=\"#item3\">Use the link https://cocl.us/new_york_dataset/newyork_data.json   to download New york 's geographical coordinates directly</a>\n",
    "\n",
    "4. <a href=\"#item4\">Aggregate New york 's geographical coordinates  with Toronto's data set  and save it for the next party</a>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary Libraries\n",
    "##### Attention: geocoder  and Folium installation takes few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folium and geocoder installed\n",
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import bs4 as bs\n",
    "import requests\n",
    "import urllib.request\n",
    "#!conda install -c conda-forge geocoder --yes # install geocoder packages \n",
    "import geocoder\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "%matplotlib inline \n",
    "from sklearn.cluster import KMeans \n",
    "from geopy.geocoders import Nominatim\n",
    "from IPython.display import Image \n",
    "from IPython.core.display import HTML \n",
    "from pandas.io.json import json_normalize\n",
    "#!conda install -c conda-forge folium=0.5.0 --yes\n",
    "import folium\n",
    "print('Folium and geocoder installed')\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1 : Use python package <a href=\"#item1\">BeautifulSoup</a>  to scrap list of postal codes of Canada\n",
    "##### Create funtion to scrap and  import all table data text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_url_scrapping(url,scrap=\"table\", attrs={\"class\": \"wikitable sortable\"}):\n",
    "    \"\"\" \n",
    "    this function helps you to scrap your url with BeautifulSoup with some parameters.\n",
    "    Please Ajust scrap and attrs parameters on your url\n",
    "    Parameters:\n",
    "      url : url you want to scrap\n",
    "      scrap : \"table\" \n",
    "      attrs : attributs of the table\n",
    "    \"\"\"\n",
    "    req = urllib.request.Request(url)\n",
    "    page = urllib.request.urlopen(req)\n",
    "    soup = bs.BeautifulSoup(page, \"html\")\n",
    "    data_table = soup.find(scrap, attrs)\n",
    "    trs = data_table.find_all('tr')\n",
    "    rows = []\n",
    "    def get_data_table_row_and_header(tr, coltag='td'): # td (data) or th (header)  \n",
    "        \"\"\"\n",
    "        this function helps you to get row of your data table that you parse.\n",
    "        Parses a html segment started with tag <table> followed by multiple <tr> (table rows) and inner <td> (table data) tags. \n",
    "        It returns a list of rows with inner columns. Accepts only one <th> (table header/data) in the first row.\n",
    "        Parameters:\n",
    "          tr = data table scrap\n",
    "          coltag :  can be 'th' for table header tag, or \"td\" for table data tag\n",
    "        \"\"\"\n",
    "        return [td.get_text(strip=True) for td in tr.find_all(coltag)]\n",
    "    headerow = get_data_table_row_and_header(trs[0], 'th')\n",
    "    if headerow: # if there is a header row include first\n",
    "        rows.append(headerow)\n",
    "        trs = trs[1:]\n",
    "    for tr in trs: # for every table row\n",
    "        rows.append(get_data_table_row_and_header(tr, 'td') ) # data row       \n",
    "    return(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of postal codes of Canada scrapping and preprocessing done !! \n",
      "List of postal codes of Canada has : 103 rows\n",
      "\n",
      "\n",
      "  Postal Code           Borough                                 Neighborhood\n",
      "0         M3A        North York                                    Parkwoods\n",
      "1         M4A        North York                             Victoria Village\n",
      "2         M5A  Downtown Toronto                    Regent Park, Harbourfront\n",
      "3         M6A        North York             Lawrence Manor, Lawrence Heights\n",
      "4         M7A  Downtown Toronto  Queen's Park, Ontario Provincial Government\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_Toronto = data_url_scrapping('https://en.wikipedia.org/wiki/List_of_postal_codes_of_Toronto:_M',scrap=\"table\", attrs={\"class\": \"wikitable sortable\"})\n",
    "data_Toronto = pd.DataFrame(data_Toronto[1:], columns=data_Toronto[0])\n",
    "data_Toronto = data_Toronto[data_Toronto.Borough!=\"Not assigned\"].reset_index(drop=True)\n",
    "print(\"List of postal codes of Toronto scrapping and preprocessing done !! \")\n",
    "print(\"List of postal codes of Toronto has : \" + str(data_Toronto.shape[0]) +\" rows\")\n",
    "print(\"\\n\")\n",
    "print(data_Toronto.head())\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 : Use the link http://cocl.us/Geospatial_data to download Canada's geographical coordinates directly\n",
    "##### after download  you merge an clean data set  with postal codes of Canada data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded!\n",
      "\n",
      "\n",
      "  Postal Code     Borough      Neighborhood   Latitude  Longitude\n",
      "0         M3A  North York         Parkwoods  43.753259 -79.329656\n",
      "1         M4A  North York  Victoria Village  43.725882 -79.315572\n",
      "\n",
      "\n",
      "##################################################\n",
      "    To make sure that data set has not null values\n",
      "##################################################\n",
      "\n",
      "\n",
      "Postal Code     0\n",
      "Borough         0\n",
      "Neighborhood    0\n",
      "Latitude        0\n",
      "Longitude       0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget -q -O 'Geospatial_Coordinates.csv' https://cocl.us/Geospatial_data\n",
    "print('Data downloaded!')\n",
    "print(\"\\n\")\n",
    "Geospatial_Coordinates = pd.read_csv('https://cocl.us/Geospatial_data/Geospatial_Coordinates.csv')\n",
    "Geospatial_Coordinates.head()\n",
    "data_Toronto_final= data_Toronto.merge(Geospatial_Coordinates)\n",
    "print(data_Toronto_final.head(2))\n",
    "print(\"\\n\")\n",
    "print(\"#\"*50)\n",
    "print(\"    To make sure that data set has not null values\")\n",
    "print(\"#\"*50)\n",
    "print(\"\\n\")\n",
    "print(data_Toronto_final.isnull().sum())\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "data_Toronto_final[\"City\"] = \"Toronto\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 : Use the link https://cocl.us/new_york_dataset/newyork_data.json  to download New york 's geographical coordinates directly\n",
    "##### after download  you merge an clean data set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download New york 's geographical coordinates done correctly !! \n",
      "It has : 306 rows\n",
      "\n",
      "\n",
      "  Borough      City   Latitude  Longitude Neighborhood Postal Code\n",
      "0   Bronx  New York  40.894705 -73.847201    Wakefield         XXX\n",
      "1   Bronx  New York  40.874294 -73.829939   Co-op City         XXX\n",
      "2   Bronx  New York  40.887556 -73.827806  Eastchester         XXX\n",
      "3   Bronx  New York  40.895437 -73.905643    Fieldston         XXX\n",
      "4   Bronx  New York  40.890834 -73.912585    Riverdale         XXX\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "New_york_data = pd.read_json('https://cocl.us/new_york_dataset/newyork_data.json', orient='index')\n",
    "New_york_data = New_york_data.T[\"features\"].values[0]\n",
    "New_york_data_final =pd.DataFrame()\n",
    "column_names = ['Borough', 'Neighborhood', 'Latitude', 'Longitude']\n",
    "for data in New_york_data:\n",
    "    borough = neighborhood_name = data['properties']['borough'] \n",
    "    neighborhood_name = data['properties']['name']\n",
    "    neighborhood_latlon = data['geometry']['coordinates']\n",
    "    neighborhood_lat = neighborhood_latlon[1]\n",
    "    neighborhood_lon = neighborhood_latlon[0]\n",
    "    New_york_data_final = New_york_data_final.append({'Postal Code':'XXX', 'Borough': borough,'Neighborhood': neighborhood_name,'Latitude': neighborhood_lat,'Longitude': neighborhood_lon, 'City':\"New York\"}, ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"download New york 's geographical coordinates done correctly !! \")\n",
    "print(\"It has : \" + str(New_york_data_final.shape[0]) +\" rows\")\n",
    "print(\"\\n\")\n",
    "print(New_york_data_final.head())\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 : Aggregate New york 's geographical coordinates  with Toronto's data set  and save it for the next party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After aggregation New york and Canada Neighborhoods dataframe has : 409 rows\n",
      "\n",
      "\n",
      "numbers of null value\n",
      "Borough         0\n",
      "City            0\n",
      "Latitude        0\n",
      "Longitude       0\n",
      "Neighborhood    0\n",
      "Postal Code     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "New_york_and_Toronto_data_final = pd.concat([New_york_data_final, data_Toronto_final], axis=0, sort=True)\n",
    "print(\"After aggregation New york and Toronto Neighborhoods dataframe has : \" + str(New_york_and_Toronto_data_final.shape[0]) +\" rows\")\n",
    "print(\"\\n\")\n",
    "New_york_and_Toronto_data_final.head()\n",
    "save_path = \"C:/Users/iamadou/Desktop/Projet ML/Certification IBM data science/Coursera_ML_Capstone_week_4/NewYork_and_Toronto_Neighborhoods.csv\"\n",
    "New_york_and_Toronto_data_final.to_csv(save_path, index=False)\n",
    "print(\"numbers of null value\")\n",
    "print(New_york_and_Toronto_data_final.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
